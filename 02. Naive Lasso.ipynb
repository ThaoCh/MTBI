{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ak-1_L_thal-mean  ak-1_L_thal-std  ak-1_L_thal-skew  ak-1_L_thal-kurt  \\\n",
      "HT102          0.605042         0.128671         -0.345832          0.060403   \n",
      "HT103          0.649086         0.133304         -0.238727         -0.237111   \n",
      "HT105          0.661849         0.170823         -0.002355         -0.595842   \n",
      "HT106          0.667329         0.128948         -0.183180         -0.034880   \n",
      "HT107          0.693921         0.155623          0.443730          0.196212   \n",
      "\n",
      "       ak-1_L_thal-etrp  ak-2_R_thal-mean  ak-2_R_thal-std  ak-2_R_thal-skew  \\\n",
      "HT102          8.750292          0.606492         0.120894         -0.525165   \n",
      "HT103          8.752230          0.700264         0.114282         -0.033532   \n",
      "HT105          8.739804          0.653673         0.146263         -0.039633   \n",
      "HT106          8.754848          0.657183         0.140268         -0.318437   \n",
      "HT107          8.749220          0.684795         0.139449         -0.211015   \n",
      "\n",
      "       ak-2_R_thal-kurt  ak-2_R_thal-etrp  ...  mk-L_Pref-mean  mk-L_Pref-std  \\\n",
      "HT102          0.772106          8.735765  ...        0.898196       0.115653   \n",
      "HT103         -0.036616          8.743465  ...        0.943797       0.129814   \n",
      "HT105          0.034464          8.731157  ...        0.881276       0.116287   \n",
      "HT106          0.092296          8.733024  ...        0.847710       0.120095   \n",
      "HT107         -0.076449          8.735454  ...        0.839157       0.103169   \n",
      "\n",
      "       mk-L_Pref-skew  mk-L_Pref-kurt  mk-L_Pref-etrp  mk-R_Pref-mean  \\\n",
      "HT102       -0.846840        0.467539        9.473894        0.841980   \n",
      "HT103       -0.982493        1.218691        9.472530        0.940279   \n",
      "HT105       -0.434682        0.155854        9.473616        0.853696   \n",
      "HT106       -0.670255       -0.090032        9.472108        0.828350   \n",
      "HT107       -0.806308        0.714794        9.474687        0.820133   \n",
      "\n",
      "       mk-R_Pref-std  mk-R_Pref-skew  mk-R_Pref-kurt  mk-R_Pref-etrp  \n",
      "HT102       0.152080       -1.027354        1.503220        9.573602  \n",
      "HT103       0.157336       -1.038395        0.866267        9.576425  \n",
      "HT105       0.128313       -0.438540        0.026787        9.579887  \n",
      "HT106       0.128875       -0.826265        0.129323        9.578769  \n",
      "HT107       0.111097       -0.414731       -0.201670        9.582148  \n",
      "\n",
      "[5 rows x 280 columns]        MTBI  T1 Letter Number  T2 Letter Number  T3 Letter Number  \\\n",
      "HT102     1               NaN               NaN               0.0   \n",
      "HT103     1               NaN               NaN               NaN   \n",
      "HT105     1               NaN               NaN               0.3   \n",
      "HT106     1               NaN               NaN               0.7   \n",
      "HT107     1               NaN               NaN              -0.3   \n",
      "\n",
      "       Digit Span Forward T1  Digit Span Forward T2  Digit Span Forward T3  \\\n",
      "HT102                  -0.33                    NaN                  -0.24   \n",
      "HT103                  -0.33                    NaN                    NaN   \n",
      "HT105                  -1.00                    NaN                  -0.96   \n",
      "HT106                   1.00                    NaN                  -0.96   \n",
      "HT107                   2.67                    NaN                   1.57   \n",
      "\n",
      "       Digit Span Backward T1  Digit Span Backward T2  Digit Span Backward T3  \\\n",
      "HT102                   -0.67                     NaN                    0.54   \n",
      "HT103                   -1.00                     NaN                     NaN   \n",
      "HT105                    1.00                     NaN                    1.21   \n",
      "HT106                   -0.67                     NaN                   -0.13   \n",
      "HT107                    2.00                     NaN                    1.21   \n",
      "\n",
      "       ...  RCFT Delayed T3  DKEFS T1  DKEFS T2  DKEFS T3  Stroop T1  \\\n",
      "HT102  ...              0.9       0.0       NaN       0.0       0.69   \n",
      "HT103  ...              NaN      -0.3       NaN       NaN       0.20   \n",
      "HT105  ...             -1.3       1.6       NaN       2.6       0.97   \n",
      "HT106  ...              0.1      -0.7       NaN       1.0       0.59   \n",
      "HT107  ...             -0.1       1.0       NaN       1.3       0.69   \n",
      "\n",
      "       Stroop T2  Stroop T3  SDMT T1  SDMT T2  SDMT T3  \n",
      "HT102        NaN       0.59     1.09      NaN     0.20  \n",
      "HT103        NaN        NaN     1.51      NaN      NaN  \n",
      "HT105        NaN       0.97    -0.62      NaN     0.62  \n",
      "HT106        NaN       0.01    -0.04      NaN     1.50  \n",
      "HT107        NaN       0.69    -1.07      NaN     0.14  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data_154.xlsx'\n",
    "label_path = 'label_154.xlsx'\n",
    "\n",
    "data = pd.read_excel(data_path, index_col=0, sheet_name=0)\n",
    "label = pd.read_excel(label_path, index_col=0, sheet_name=0)\n",
    "features = np.array (list(data.columns))\n",
    "\n",
    "predict = [ 'T1 Letter Number']\n",
    "\n",
    "negative_idx = np.array ((np.arange(22) + 27).tolist() + (np.arange(48) + 106).tolist())\n",
    "\n",
    "print(data.head(), label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for p in predict:\n",
    "\n",
    "    X = data.iloc[negative_idx]\n",
    "    y = (label.iloc[negative_idx])[p]\n",
    "        \n",
    "    features = np.array (list(X.columns))\n",
    "    \n",
    "    drop = y.notnull()\n",
    "\n",
    "    X = X[drop]\n",
    "    y = y[drop]\n",
    "    \n",
    "    X = (X.values)\n",
    "    y = (y.values)\n",
    "    \n",
    "    nfold = 5\n",
    "    nrepeats=25\n",
    "    kf = RepeatedKFold(n_splits=nfold, n_repeats=nrepeats)\n",
    "    \n",
    "    scores = np.zeros([nfold*nrepeats])\n",
    "    \n",
    "    a = 1\n",
    "    \n",
    "    for isplit, Ind in enumerate(tqdm(kf.split(X))):\n",
    "\n",
    "        # Get the training data in the split\n",
    "        Itr, Its = Ind\n",
    "\n",
    "        Xtr = X[Itr]\n",
    "        ytr = y[Itr]\n",
    "        Xts = X[Its]\n",
    "        yts = y[Its]\n",
    "\n",
    "        regr = Lasso(alpha=a, max_iter=50000)\n",
    "        regr.fit(Xtr, ytr)\n",
    "        yhat = regr.predict(Xts)\n",
    "        scores[isplit] = r2_score(yts, yhat)\n",
    "\n",
    "    print('For np {0}, the mean r2 scores for prediction is {1:.6f} with std = {2:.6f}'.format(p, np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    regr = Lasso(alpha=a, max_iter=50000)\n",
    "    regr.fit(X, y)\n",
    "\n",
    "    lasso_coeff = regr.coef_\n",
    "    # showing the stem graph of lasso coeff\n",
    "    plt.stem(np.arange(*lasso_coeff.shape), lasso_coeff)\n",
    "    plt.show()\n",
    "    \n",
    "    print('For np {0}, the related features are {1}'.format (p, features[np.nonzero(lasso_coeff)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in predict:\n",
    "\n",
    "    X = data\n",
    "    y = label[p]\n",
    "\n",
    "    features = np.array (list(X.columns))\n",
    "    \n",
    "    drop = y.notnull()\n",
    "\n",
    "    X = X[drop]\n",
    "    y = y[drop]\n",
    "    \n",
    "    X = (X.values)\n",
    "    y = (y.values)\n",
    "    \n",
    "    nfold = 5\n",
    "    nrepeats = 2\n",
    "    \n",
    "    kf = RepeatedKFold(n_splits=nfold, n_repeats=nrepeats)\n",
    "    \n",
    "    model = svm.SVR(C=25, epsilon=0.1, kernel='linear', degree=4, gamma=10, tol=0.001, cache_size=200, max_iter=-1)\n",
    "    \n",
    "    rfecv = RFECV(estimator=model, step=10, cv=kf, scoring='r2', verbose=1, n_jobs=-1)\n",
    "    rfecv.fit(X, y)\n",
    "\n",
    "    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros([nfold*nrepeats])\n",
    "\n",
    "for isplit, Ind in enumerate(tqdm(kf.split(X))):\n",
    "    \n",
    "    # Get the training data in the split\n",
    "    Itr, Its = Ind\n",
    "    \n",
    "    Xtr = X[Itr]\n",
    "    ytr = y[Itr]\n",
    "    Xts = X[Its]\n",
    "    yts = y[Its]\n",
    "    \n",
    "    regr = Lasso(alpha=0.005, max_iter=10000)\n",
    "    regr.fit(Xtr, ytr)\n",
    "    scores[isplit] = regr.score(Xts, yts)\n",
    "\n",
    "print('the mean r2 scores for prediction is {0:.6f} with std = {1:.6f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = Lasso(alpha=0.005, max_iter=10000)\n",
    "regr.fit(X, y)\n",
    "\n",
    "lasso_coeff = regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(np.arange(*lasso_coeff.shape), lasso_coeff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the only related features are {}'.format (features[np.nonzero(lasso_coeff)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_forward_SVM(F, y, num_feature, num_selected, num_repeats, num_test, C_val, Gamma_val, eps_val):\n",
    "    '''\n",
    "    Greedy Forward SVM by Dr. Alp\n",
    "    Args:\n",
    "        F: data\n",
    "        y: label\n",
    "        num_feature: number of feature in total. should be 120 but only 100\n",
    "        num_selected: number of feature selected\n",
    "        num_repeats: iter of repeat to avoid noise\n",
    "        num_test: number of test sample\n",
    "        C_val: c value as SVM hypter parameter\n",
    "        Gamma_val: gamma value as SVM hyper parameter\n",
    "        eps_val: eplison value as SVM hyper parameter\n",
    "    '''\n",
    "    best_acc_featsize = np.zeros((num_feature,))  ### accuracy with best subset of different sizes\n",
    "    all_feat_remained = np.arange(num_feature)\n",
    "    feat_order = list()\n",
    "\n",
    "    num_samples = F.shape[0]\n",
    "\n",
    "    for i in range(num_selected):  ## adds one feature per step\n",
    "        # iterating through all possible i\n",
    "\n",
    "        train_acc_cur = np.zeros((len(all_feat_remained), num_repeats))\n",
    "        test_acc_cur = np.zeros((len(all_feat_remained), num_repeats))\n",
    "        train_acc_avg = np.zeros((len(all_feat_remained),))\n",
    "        test_acc_avg = np.zeros((len(all_feat_remained),))\n",
    "        # print(\"%d-th feature selection\" % ( i+1) )\n",
    "\n",
    "        for j in range(len(all_feat_remained)):  ## selects one feature out of the remaining ones\n",
    "\n",
    "            cur_feat_list = deepcopy(feat_order)\n",
    "            cur_feat_list.append(all_feat_remained[j])\n",
    "            X = F[:, cur_feat_list]\n",
    "            # print(\"%d-th feature selection and feature list= [%s]\" % ( i+1, ', '.join(map(str, cur_feat_list))))\n",
    "\n",
    "            for iter in range(num_repeats):\n",
    "                # print(\"%d-th feature selection and %d-th iteration and feature list= [%s]\" % ( i+1, iter+1,', '.join(map(str, cur_feat_list))))\n",
    "\n",
    "                np.random.seed(3 * iter + 10)\n",
    "                inds = np.random.choice(len(y), num_test)\n",
    "\n",
    "                X_test = X[inds, :]\n",
    "                y_test = y[inds]\n",
    "                X_train = np.delete(X, inds, 0)\n",
    "                y_train = np.delete(y, inds)\n",
    "\n",
    "                clf = svm.SVR(C=C_val, epsilon=eps_val, kernel='rbf', degree=4, gamma=Gamma_val, tol=0.001,\n",
    "                              cache_size=200, max_iter=-1)\n",
    "                clf.fit(X_train, y_train)\n",
    "                predicted_train_labels = clf.predict(X_train)\n",
    "                train_score = clf.score(X_train, y_train)\n",
    "                # train_error= sum( [1. for k in pred_diff_train if k != 0])/len(predicted_train_labels)\n",
    "                train_acc_cur[j, iter] = train_score\n",
    "                predicted_test_labels = clf.predict(X_test)\n",
    "                test_score = clf.score(X_test, y_test)\n",
    "                # test_error= sum( [1. for k in pred_diff_test if k != 0])/len(predicted_test_labels)\n",
    "                test_acc_cur[j, iter] = test_score\n",
    "                # print(\"%d-th feature, current list [%s], and its acc= %f\" % ( j+1, ', '.join(map(str, cur_feat_list)), test_acc_cur[ j, iter] ))\n",
    "\n",
    "        for k in range(len(all_feat_remained)):\n",
    "            train_acc_avg[k] = np.mean(train_acc_cur[k, :])\n",
    "            test_acc_avg[k] = np.mean(test_acc_cur[k, :])\n",
    "\n",
    "        best_acc_featsize[i] = np.max(test_acc_avg)\n",
    "        best_testacc_ind = np.unravel_index(test_acc_avg.argmax(), test_acc_avg.shape)\n",
    "        feat_order.append(all_feat_remained[best_testacc_ind])\n",
    "        # print(\" current best feature index= %d\" %  (all_feat_remained[best_testacc_ind]) )\n",
    "\n",
    "        all_feat_remained = np.delete(all_feat_remained, best_testacc_ind, 0)\n",
    "\n",
    "    return feat_order, best_acc_featsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = label['Digit Span Backward T1']\n",
    "\n",
    "features = np.array (list(X.columns))\n",
    "\n",
    "drop = y.notnull()\n",
    "\n",
    "X = X[drop]\n",
    "y = y[drop]\n",
    "\n",
    "X = (X.values)\n",
    "y = (y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "( 31.62278 , 0.31623 ) value of (C, Gamma), and best feat indices= [ 29 242  12 258  25   5  19  24 164 259]\n",
      "maximum test accuracy= 0.412, achieved by using 8 features and ( C, Gamma, eps)= ( 31.62278, 0.31623, 0.00500) from 14 metrics\n",
      "Selected feature for 3xiter= [ 29. 242.  12. 258.  25.   5.  19.  24.]\n",
      "['ak-L_Pref-etrp' 'md-R_Pref-skew' 'ak-CC_Body_mask-skew'\n",
      " 'mk-CC_Body_mask-kurt' 'ak-L_Pref-mean' 'ak-2_R_thal-mean'\n",
      " 'ak-CC_Genu_mask-etrp' 'ak-CC_Splenium_mask-etrp']\n",
      "total time= 112.98960018157959\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "num_feature = X.shape[1]\n",
    "num_test = 20\n",
    "num_repeats = 10  ## shows number of times we shuffle the data and test on testing\n",
    "train_accuracies = [0] * num_repeats\n",
    "test_accuracies = [0] * num_repeats\n",
    "\n",
    "tot_num = X.shape[0]\n",
    "\n",
    "num_selected = 10\n",
    "eps = 0.01\n",
    "\n",
    "C_range = np.logspace(-3, 3, num=5)\n",
    "gamma_range = np.logspace(-5, 4, 5)\n",
    "\n",
    "# C_range = np.array([31.62278])\n",
    "# gamma_range = np.array([0.31623])\n",
    "\n",
    "test_acc_all = np.zeros((C_range.shape[0], gamma_range.shape[0], num_feature))\n",
    "selected_feat = np.zeros((C_range.shape[0], gamma_range.shape[0], num_selected))\n",
    "\n",
    "print(\"Start\")\n",
    "for i in range(len(C_range)):\n",
    "    for j in range(len(gamma_range)):\n",
    "        a1, a2 = greedy_forward_SVM(X, y, num_feature, num_selected, num_repeats, num_test, C_range[i], gamma_range[j],\n",
    "                                    eps)\n",
    "        a3 = np.asarray(a1)\n",
    "        test_acc_all[i, j, :] = a2\n",
    "        selected_feat[i, j, :] = a3\n",
    "        print(\"(\", C_range[i], \",\", gamma_range[j], \") value of (C, Gamma), and best feat indices=\", a3)\n",
    "\n",
    "max_ind = np.unravel_index(test_acc_all.argmax(), test_acc_all.shape)\n",
    "print(\"maximum test accuracy= %.3f, achieved by using %d features and ( C, Gamma, eps)= ( %.5f, %.5f, %.5f) from 14 metrics\" % (\n",
    "test_acc_all[max_ind], max_ind[2] + 1, C_range[max_ind[0]], gamma_range[max_ind[1]], eps))\n",
    "print(\"Selected feature for 3xiter=\", selected_feat[max_ind[0], max_ind[1], 0:max_ind[2] + 1])\n",
    "print(features[np.array(selected_feat[max_ind[0], max_ind[1], 0:max_ind[2] + 1], dtype=np.int)])\n",
    "# print(\"\\nMaximum Train Accuracy with 100 iteration: %f \" % np.max(train_acc_all), \"%\")\n",
    "# print(\"\\nMaximum Test Accuracy: %f, by feature indices= %s \" % ( np.max(test_acc_avg), subset_indices[best_testacc_ind[0]] ) )\n",
    "\n",
    "# print(\"\\nall accuracies:\", test_acc_avg)\n",
    "\n",
    "end_time = time.time()\n",
    "tot_time = end_time - start_time\n",
    "print(\"total time=\", tot_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IVP",
   "language": "python",
   "name": "cs231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
