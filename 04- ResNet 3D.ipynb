{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datautility import *\n",
    "from dataset import *\n",
    "from vnet import *\n",
    "from training import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, sampler, SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#------------------------------- GLOBAL VARIABLES -------------------------------------#\n",
    "\n",
    "USE_GPU = True\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 6\n",
    "NUM_TRAIN = 80 # 80 training sample and 37 validation sample\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Training new data only\n",
    "* Positive: 67 samples\n",
    "* Negative: 50 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 subjects with 12 metrics each\n"
     ]
    }
   ],
   "source": [
    "positive_idx = np.arange(73) + 1\n",
    "positive_idx = np.delete(positive_idx, [8, 15, 16, 17, 29, 33])\n",
    "\n",
    "negative_idx = np.arange(53) + 1\n",
    "negative_idx = np.delete(negative_idx, [14, 15, 16])\n",
    "\n",
    "image_dict = np.concatenate((positive_idx, negative_idx))\n",
    "\n",
    "metric = ['ad', 'ak', 'awf', 'eas_De_par', 'eas_De_perp', 'eas_tort', 'FA', 'ias_Da', 'md', 'mk', 'rd', 'rk']\n",
    "print('{} subjects with {} metrics each'.format(len(image_dict), len(metric)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regen = False\n",
    "\n",
    "if regen:\n",
    "    data_index = np.arange(107)\n",
    "    data_idnex = np.random.shuffle(data_index)\n",
    "    print(list(data_index))\n",
    "    \n",
    "else:\n",
    "    image_index = np.array ([40, 64, 58, 103, 19, 5, 68, 56, 66, 10, 75, 43, 1, 81, 83, 49, 11, 80, 102,\\\n",
    "                             82, 69, 13, 4, 61, 70, 100, 23, 72, 55, 16, 90, 53, 78, 21, 39, 25, 74, 42, 22,\\\n",
    "                             79, 48, 24, 2, 8, 9, 59, 0, 3, 91, 84, 15, 95, 106, 27, 94, 65, 96, 63, 7, 71,\\\n",
    "                             57, 30, 86, 62, 31, 93, 99, 104, 51, 50, 26, 17, 46, 35, 38, 60, 87, 20, 67, 77,\\\n",
    "                             45, 34, 44, 54, 41, 105, 88, 98, 85, 97, 6, 29, 101, 73, 28, 36, 76, 18, 89, 52,\\\n",
    "                             32, 14, 33, 47, 92, 37, 12]\n",
    "                            )\n",
    "\n",
    "dataset_image = MTBIDataset(image_dict, \n",
    "                            metric, \n",
    "                            transform=transforms.Compose([\n",
    "                                 downSample(2),\n",
    "                                 RandomAffine(15, 10)\n",
    "                            ]),\n",
    "                     )\n",
    "\n",
    "#-------------------------CREATE DATA LOADER FOR TRAIN AND VAL------------------------#\n",
    "\n",
    "data_size = len(dataset_image)\n",
    "\n",
    "train_loader = DataLoader(dataset_image, batch_size=BATCH_SIZE, \\\n",
    "                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)),\\\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(dataset_image, batch_size=BATCH_SIZE,\n",
    "                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN,data_size)),\\\n",
    "                    num_workers=NUM_WORKERS)\n",
    "\n",
    "# data_set = MTBIDataset(image_dict, metric, transform=None, mode='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print(i_batch, sample_batched['image'].size(), \\\n",
    "          sample_batched['label'].size())\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        # show_batch_image(sample_batched['image'],sample_batched['label'],BATCH_SIZE)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------NEW MODEL INIT WEIGHT--------------------------------------#\n",
    "\n",
    "LoadCKP = False\n",
    "CKPPath = 'checkpoint2019-03-31 13:33:50.772063.pth'\n",
    "\n",
    "model = LNet(img_size=(64, 96, 64))\n",
    "model.apply(weights_init)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=50, verbose=True)\n",
    "\n",
    "if LoadCKP:\n",
    "    model, optimizer, scheduler = loadckp(model, optimizer, scheduler, CKPPath, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 finished ! Training Loss: 0.6226080473926332\n",
      "     validation loss = 27.6310\n",
      "Checkpoint 1 saved !\n",
      "Epoch 1 finished ! Training Loss: 0.6891201039155325\n",
      "     validation loss = 27.3388\n",
      "Epoch 2 finished ! Training Loss: 0.49541984995206195\n",
      "     validation loss = 2.7888\n",
      "Epoch 3 finished ! Training Loss: 0.5574507349067264\n",
      "     validation loss = 2.8100\n",
      "Epoch 4 finished ! Training Loss: 0.5734136700630188\n",
      "     validation loss = 1.8156\n",
      "Epoch 5 finished ! Training Loss: 0.6257185108131833\n",
      "     validation loss = 1.2421\n",
      "Epoch 6 finished ! Training Loss: 0.5665172735850016\n",
      "     validation loss = 3.0602\n",
      "Epoch 7 finished ! Training Loss: 0.5774756454759173\n",
      "     validation loss = 2.5544\n",
      "Epoch 8 finished ! Training Loss: 0.5412749151388804\n",
      "     validation loss = 1.4302\n",
      "Epoch 9 finished ! Training Loss: 0.6114688714345297\n",
      "     validation loss = 2.2342\n",
      "Epoch 10 finished ! Training Loss: 0.5701064434316423\n",
      "     validation loss = 1.9906\n",
      "Epoch 11 finished ! Training Loss: 0.5396849281258054\n",
      "     validation loss = 1.4106\n",
      "Epoch 12 finished ! Training Loss: 0.5506198075082567\n",
      "     validation loss = 1.8225\n",
      "Epoch 13 finished ! Training Loss: 0.5509920467933019\n",
      "     validation loss = 1.4232\n",
      "Epoch 14 finished ! Training Loss: 0.4831916126939986\n",
      "     validation loss = 1.0420\n",
      "Epoch 15 finished ! Training Loss: 0.6106975989209281\n",
      "     validation loss = 1.5993\n",
      "Epoch 16 finished ! Training Loss: 0.5352549834383858\n",
      "     validation loss = 2.2819\n",
      "Epoch 17 finished ! Training Loss: 0.49394167628553176\n",
      "     validation loss = 1.8884\n",
      "Epoch 18 finished ! Training Loss: 0.5851621197329627\n",
      "     validation loss = 1.5834\n",
      "Epoch 19 finished ! Training Loss: 0.637334937022792\n",
      "     validation loss = 1.5161\n",
      "Epoch 20 finished ! Training Loss: 0.5535570101605521\n",
      "     validation loss = 1.7178\n",
      "Epoch 21 finished ! Training Loss: 0.5131100647979312\n",
      "     validation loss = 2.0742\n",
      "Epoch 22 finished ! Training Loss: 0.5058133486244414\n",
      "     validation loss = 2.1706\n",
      "Epoch 23 finished ! Training Loss: 0.5400584389766058\n",
      "     validation loss = 1.5150\n",
      "Epoch 24 finished ! Training Loss: 0.574142724275589\n",
      "     validation loss = 1.7215\n",
      "Epoch 25 finished ! Training Loss: 0.5148058467441134\n",
      "     validation loss = 1.9332\n",
      "Epoch 26 finished ! Training Loss: 0.4792545305358039\n",
      "     validation loss = 1.7912\n",
      "Epoch 27 finished ! Training Loss: 0.5278439637687471\n",
      "     validation loss = 2.0128\n"
     ]
    }
   ],
   "source": [
    "loss = nn.BCELoss()\n",
    "\n",
    "train(model, train_loader, validation_loader, optimizer, scheduler, device, dtype, lossFun=loss, epochs=500, streopch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch=1.0, CUDA=10.1",
   "language": "python",
   "name": "cs231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
