{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datautility import *\n",
    "from dataset import *\n",
    "from vnet import *\n",
    "from training import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, sampler, SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#------------------------------- GLOBAL VARIABLES -------------------------------------#\n",
    "\n",
    "USE_GPU = True\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 6\n",
    "NUM_TRAIN = 80 # 80 training sample and 37 validation sample\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Training new data only\n",
    "* Positive: 67 samples\n",
    "* Negative: 50 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 subjects with 4 metrics each\n"
     ]
    }
   ],
   "source": [
    "positive_idx = np.arange(73) + 1\n",
    "positive_idx = np.delete(positive_idx, [8, 15, 16, 17, 29, 33])\n",
    "\n",
    "negative_idx = np.arange(53) + 1\n",
    "negative_idx = np.delete(negative_idx, [14, 15, 16])\n",
    "\n",
    "image_dict = np.concatenate((positive_idx, negative_idx))\n",
    "metric = ['ak', 'md', 'ad', 'FA'] # 8 Channels selected from Paper\n",
    "\n",
    "# metric = ['ak', 'awf', 'eas_De_par', 'eas_De_perp', 'FA', 'ias_Da', 'md', 'mk'] # 8 Channels selected from Paper\n",
    "print('{} subjects with {} metrics each'.format(len(image_dict), len(metric)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regen = False\n",
    "\n",
    "if regen:\n",
    "    data_index = np.arange(117)\n",
    "    data_idnex = np.random.shuffle(data_index)\n",
    "    print(list(data_index))\n",
    "    \n",
    "else:\n",
    "    data_idnex = np.array ([10, 22, 1, 86, 74, 109, 54, 59, 75, 4, 26, 5, 79, 40, 39, 112,\\\n",
    "                            104, 51, 116, 80, 77, 57, 3, 85, 29, 55, 18, 87, 50, 27, 0, 108,\\\n",
    "                            45, 34, 46, 15, 6, 102, 68, 64, 32, 89, 2, 100, 25, 67, 70, 113,\\\n",
    "                            81, 56, 8, 110, 35, 47, 115, 23, 88, 63, 17, 99, 49, 30, 92, 78,\\\n",
    "                            37, 19, 48, 24, 28, 103, 73, 95, 96, 20, 11, 9, 33, 60, 7, 76,\\\n",
    "                            71, 93, 65, 106, 53, 13, 111, 101, 12, 42, 16, 91, 43, 84, 97,\\\n",
    "                            72, 41, 82, 83, 66, 94, 31, 90, 98, 114, 107, 44, 58, 52, 61, 69,\\\n",
    "                            38, 36, 62, 105, 14, 21]\n",
    "                            )\n",
    "\n",
    "dataset_image = MTBIDataset(data_idnex,\n",
    "                            image_dict, \n",
    "                            metric, \n",
    "                            transform=transforms.Compose([\n",
    "                                 # RandomAffine(0, 1)\n",
    "                            ]),\n",
    "                     )\n",
    "\n",
    "#-------------------------CREATE DATA LOADER FOR TRAIN AND VAL------------------------#\n",
    "\n",
    "data_size = len(dataset_image)\n",
    "\n",
    "train_loader = DataLoader(dataset_image, batch_size=BATCH_SIZE, \\\n",
    "                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)),\\\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(dataset_image, batch_size=BATCH_SIZE,\n",
    "                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN,data_size)),\\\n",
    "                    num_workers=NUM_WORKERS)\n",
    "\n",
    "# data_set = MTBIDataset(image_dict, metric, transform=None, mode='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([16, 4, 64, 96, 64]) torch.Size([16, 1])\n",
      "1 torch.Size([16, 4, 64, 96, 64]) torch.Size([16, 1])\n",
      "2 torch.Size([5, 4, 64, 96, 64]) torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(validation_loader):\n",
    "    print(i_batch, sample_batched['image'].size(), \\\n",
    "          sample_batched['label'].size())\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 8:\n",
    "        # show_batch_image(sample_batched['image'],sample_batched['label'],BATCH_SIZE)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------NEW MODEL INIT WEIGHT--------------------------------------#\n",
    "\n",
    "LoadCKP = False\n",
    "CKPPath = 'checkpoint2019-03-31 13:33:50.772063.pth'\n",
    "\n",
    "model = LNet1(img_size=(64, 96, 64))\n",
    "model.apply(weights_init)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=50, verbose=True)\n",
    "\n",
    "if LoadCKP:\n",
    "    model, optimizer, scheduler = loadckp(model, optimizer, scheduler, CKPPath, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 finished ! Training Loss: 1.1974, acc: 0.4375\n",
      "     validation loss = 5.7756, accuracy = 0.6042\n",
      "Checkpoint 1 saved !\n",
      "Epoch 1 finished ! Training Loss: 0.7502, acc: 0.5375\n",
      "     validation loss = 2.3286, accuracy = 0.6458\n",
      "Epoch 2 finished ! Training Loss: 0.6885, acc: 0.6000\n",
      "     validation loss = 1.0935, accuracy = 0.4042\n",
      "Epoch 3 finished ! Training Loss: 0.6827, acc: 0.5750\n",
      "     validation loss = 1.0842, accuracy = 0.6000\n",
      "Epoch 4 finished ! Training Loss: 0.7058, acc: 0.5250\n",
      "     validation loss = 0.7943, accuracy = 0.6208\n",
      "Epoch 5 finished ! Training Loss: 0.6936, acc: 0.5875\n",
      "     validation loss = 0.8821, accuracy = 0.4417\n",
      "Epoch 6 finished ! Training Loss: 0.6611, acc: 0.6500\n",
      "     validation loss = 0.8460, accuracy = 0.4875\n",
      "Epoch 7 finished ! Training Loss: 0.6667, acc: 0.6500\n",
      "     validation loss = 0.7274, accuracy = 0.5333\n",
      "Epoch 8 finished ! Training Loss: 0.7012, acc: 0.5625\n"
     ]
    }
   ],
   "source": [
    "loss = nn.BCELoss()\n",
    "\n",
    "train(model, train_loader, validation_loader, optimizer, scheduler, device, dtype, lossFun=loss, epochs=5000, streopch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch=1.0, CUDA=10.1",
   "language": "python",
   "name": "cs231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
