{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pymrmr\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ak-left_rostral-mean  ak-left_rostral-std  ak-left_rostral-skew  \\\n",
      "HT102              0.743415             0.132570             -0.139329   \n",
      "HT103              0.817765             0.136033              0.149619   \n",
      "HT105              0.716597             0.118742              0.327498   \n",
      "HT106              0.782687             0.131543              0.061009   \n",
      "HT107              0.731944             0.129686              0.131464   \n",
      "\n",
      "       ak-left_rostral-kurt  ak-left_rostral-etrp  ak-right_rostral-mean  \\\n",
      "HT102              0.018893              5.381851               0.781545   \n",
      "HT103              1.238020              5.542772               0.790646   \n",
      "HT105              0.808425              5.523633               0.725885   \n",
      "HT106              0.821854              5.457917               0.748640   \n",
      "HT107              0.158863              5.548673               0.698416   \n",
      "\n",
      "       ak-right_rostral-std  ak-right_rostral-skew  ak-right_rostral-kurt  \\\n",
      "HT102              0.141145               0.135048              -0.007931   \n",
      "HT103              0.165108               0.190100               1.223869   \n",
      "HT105              0.119918              -0.418822               2.676299   \n",
      "HT106              0.140050              -0.027460               2.157885   \n",
      "HT107              0.129014               0.234349               0.483286   \n",
      "\n",
      "       ak-right_rostral-etrp  ...  mk-right_caudal-mean  mk-right_caudal-std  \\\n",
      "HT102               5.548081  ...              0.943713             0.148402   \n",
      "HT103               5.668128  ...              0.942446             0.144605   \n",
      "HT105               5.498841  ...              0.881773             0.136350   \n",
      "HT106               5.304922  ...              0.921833             0.160872   \n",
      "HT107               5.543544  ...              0.886850             0.138566   \n",
      "\n",
      "       mk-right_caudal-skew  mk-right_caudal-kurt  mk-right_caudal-etrp  \\\n",
      "HT102             -0.661986              0.894357              6.034336   \n",
      "HT103             -0.547620              1.047708              5.938316   \n",
      "HT105             -0.555354              0.559814              6.150811   \n",
      "HT106             -0.841533              0.970919              5.952324   \n",
      "HT107             -0.536177              0.448112              6.248735   \n",
      "\n",
      "       mk-corpus_callosum-mean  mk-corpus_callosum-std  \\\n",
      "HT102                 1.038792                0.212341   \n",
      "HT103                 1.052511                0.219208   \n",
      "HT105                 1.035490                0.189303   \n",
      "HT106                 1.010525                0.230218   \n",
      "HT107                 0.935684                0.215281   \n",
      "\n",
      "       mk-corpus_callosum-skew  mk-corpus_callosum-kurt  \\\n",
      "HT102                -0.086123                -0.296385   \n",
      "HT103                -0.145536                 0.102694   \n",
      "HT105                -0.385818                -0.257393   \n",
      "HT106                 0.040488                -0.026569   \n",
      "HT107                -0.185256                 0.002190   \n",
      "\n",
      "       mk-corpus_callosum-etrp  \n",
      "HT102                 6.942690  \n",
      "HT103                 6.797515  \n",
      "HT105                 6.975609  \n",
      "HT106                 6.897039  \n",
      "HT107                 6.962552  \n",
      "\n",
      "[5 rows x 280 columns]        Unnamed: 0.1  T1 Letter Number  T2 Letter Number  T3 Letter Number  \\\n",
      "HT102             0               NaN               NaN               0.0   \n",
      "HT103             1               NaN               NaN               NaN   \n",
      "HT105             3               NaN               NaN               0.3   \n",
      "HT106             4               NaN               NaN               0.7   \n",
      "HT107             5               NaN               NaN              -0.3   \n",
      "\n",
      "       Digit Span Forward T1  Digit Span Forward T2  Digit Span Forward T3  \\\n",
      "HT102                  -0.33                    NaN                  -0.24   \n",
      "HT103                  -0.33                    NaN                    NaN   \n",
      "HT105                  -1.00                    NaN                  -0.96   \n",
      "HT106                   1.00                    NaN                  -0.96   \n",
      "HT107                   2.67                    NaN                   1.57   \n",
      "\n",
      "       Digit Span Backward T1  Digit Span Backward T2  Digit Span Backward T3  \\\n",
      "HT102                   -0.67                     NaN                    0.54   \n",
      "HT103                   -1.00                     NaN                     NaN   \n",
      "HT105                    1.00                     NaN                    1.21   \n",
      "HT106                   -0.67                     NaN                   -0.13   \n",
      "HT107                    2.00                     NaN                    1.21   \n",
      "\n",
      "       ...  RCFT Delayed T3  DKEFS T1  DKEFS T2  DKEFS T3  Stroop T1  \\\n",
      "HT102  ...              0.9       0.0       NaN       0.0       0.69   \n",
      "HT103  ...              NaN      -0.3       NaN       NaN       0.20   \n",
      "HT105  ...             -1.3       1.6       NaN       2.6       0.97   \n",
      "HT106  ...              0.1      -0.7       NaN       1.0       0.59   \n",
      "HT107  ...             -0.1       1.0       NaN       1.3       0.69   \n",
      "\n",
      "       Stroop T2  Stroop T3  SDMT T1  SDMT T2  SDMT T3  \n",
      "HT102        NaN       0.59     1.09      NaN     0.20  \n",
      "HT103        NaN        NaN     1.51      NaN      NaN  \n",
      "HT105        NaN       0.97    -0.62      NaN     0.62  \n",
      "HT106        NaN       0.01    -0.04      NaN     1.50  \n",
      "HT107        NaN       0.69    -1.07      NaN     0.14  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "mask = 'new'\n",
    "space = 'subject'\n",
    "\n",
    "if space == 'template':\n",
    "    negative_idx = np.array ((np.arange(22) + 27).tolist() + (np.arange(48) + 106).tolist())\n",
    "    label_path = 'label_154.xlsx'\n",
    "    if mask == 'new':\n",
    "        data_path = 'data_154_newmask.xlsx'\n",
    "    elif mask == 'old':\n",
    "        data_path = 'data_154_oldmask.xlsx'\n",
    "    else:\n",
    "        print('mask {} not supported'.format(mask))\n",
    "    \n",
    "elif space == 'subject':\n",
    "    negative_idx = np.array ((np.arange(22) + 27).tolist() + (np.arange(35) + 97).tolist())\n",
    "    label_path = 'label_132.xlsx'\n",
    "    if mask == 'new':\n",
    "        data_path = 'data_132_newmask_subjectspace.xlsx'\n",
    "    elif mask == 'old':\n",
    "        data_path = 'data_132_oldmask_subjectspace.xlsx'\n",
    "    else:\n",
    "        print('space {} not supported'.format(mask))\n",
    "else:\n",
    "    print('mask {} not supported'.format(space))\n",
    "    \n",
    "data = pd.read_excel(data_path, index_col=0, sheet_name=0)\n",
    "label = pd.read_excel(label_path, index_col=0, sheet_name=0)\n",
    "features = np.array (list(data.columns))\n",
    "\n",
    "predict = 'T1 Letter Number'\n",
    "\n",
    "print(data.head(), label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_forward_SVM(F, y, num_feature, num_selected, num_repeats, num_test, C_val, Gamma_val, eps_val):\n",
    "    '''\n",
    "    Greedy Forward SVM by Dr. Alp\n",
    "    Args:\n",
    "        F: data\n",
    "        y: label\n",
    "        num_feature: number of feature in total. should be 120 but only 100\n",
    "        num_selected: number of feature selected\n",
    "        num_repeats: iter of repeat to avoid noise\n",
    "        num_test: number of test sample\n",
    "        C_val: c value as SVM hypter parameter\n",
    "        Gamma_val: gamma value as SVM hyper parameter\n",
    "        eps_val: eplison value as SVM hyper parameter\n",
    "    '''\n",
    "    best_acc_featsize = np.zeros((num_feature,))  ### accuracy with best subset of different sizes\n",
    "    all_feat_remained = np.arange(num_feature)\n",
    "    feat_order = list()\n",
    "\n",
    "    num_samples = F.shape[0]\n",
    "\n",
    "    for i in range(num_selected):  ## adds one feature per step\n",
    "        # iterating through all possible i\n",
    "\n",
    "        train_acc_cur = np.zeros((len(all_feat_remained), num_repeats))\n",
    "        test_acc_cur = np.zeros((len(all_feat_remained), num_repeats))\n",
    "        train_acc_avg = np.zeros((len(all_feat_remained),))\n",
    "        test_acc_avg = np.zeros((len(all_feat_remained),))\n",
    "        # print(\"%d-th feature selection\" % ( i+1) )\n",
    "\n",
    "        for j in range(len(all_feat_remained)):  ## selects one feature out of the remaining ones\n",
    "\n",
    "            cur_feat_list = deepcopy(feat_order)\n",
    "            cur_feat_list.append(all_feat_remained[j])\n",
    "            X = F[:, cur_feat_list]\n",
    "            # print(\"%d-th feature selection and feature list= [%s]\" % ( i+1, ', '.join(map(str, cur_feat_list))))\n",
    "\n",
    "            for iter in range(num_repeats):\n",
    "                # print(\"%d-th feature selection and %d-th iteration and feature list= [%s]\" % ( i+1, iter+1,', '.join(map(str, cur_feat_list))))\n",
    "\n",
    "                np.random.seed(3 * iter + 10)\n",
    "                inds = np.random.choice(len(y), num_test)\n",
    "\n",
    "                X_test = X[inds, :]\n",
    "                y_test = y[inds]\n",
    "                X_train = np.delete(X, inds, 0)\n",
    "                y_train = np.delete(y, inds)\n",
    "\n",
    "                clf = svm.SVR(C=C_val, epsilon=eps_val, kernel='rbf', degree=4, gamma=Gamma_val, tol=0.001,\n",
    "                              cache_size=200, max_iter=-1)\n",
    "                clf.fit(X_train, y_train)\n",
    "                predicted_train_labels = clf.predict(X_train)\n",
    "                train_score = clf.score(X_train, y_train)\n",
    "                # train_error= sum( [1. for k in pred_diff_train if k != 0])/len(predicted_train_labels)\n",
    "                train_acc_cur[j, iter] = train_score\n",
    "                predicted_test_labels = clf.predict(X_test)\n",
    "                test_score = clf.score(X_test, y_test)\n",
    "                # test_error= sum( [1. for k in pred_diff_test if k != 0])/len(predicted_test_labels)\n",
    "                test_acc_cur[j, iter] = test_score\n",
    "                # print(\"%d-th feature, current list [%s], and its acc= %f\" % ( j+1, ', '.join(map(str, cur_feat_list)), test_acc_cur[ j, iter] ))\n",
    "\n",
    "        for k in range(len(all_feat_remained)):\n",
    "            train_acc_avg[k] = np.mean(train_acc_cur[k, :])\n",
    "            test_acc_avg[k] = np.mean(test_acc_cur[k, :])\n",
    "\n",
    "        best_acc_featsize[i] = np.max(test_acc_avg)\n",
    "        best_testacc_ind = np.unravel_index(test_acc_avg.argmax(), test_acc_avg.shape)\n",
    "        feat_order.append(all_feat_remained[best_testacc_ind])\n",
    "        # print(\" current best feature index= %d\" %  (all_feat_remained[best_testacc_ind]) )\n",
    "\n",
    "        all_feat_remained = np.delete(all_feat_remained, best_testacc_ind, 0)\n",
    "\n",
    "    return feat_order, best_acc_featsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ak-left_rostral-mean', 'ak-left_rostral-std', 'ak-left_rostral-skew',\n",
      "       'ak-left_rostral-kurt', 'ak-left_rostral-etrp', 'ak-right_rostral-mean',\n",
      "       'ak-right_rostral-std', 'ak-right_rostral-skew',\n",
      "       'ak-right_rostral-kurt', 'ak-right_rostral-etrp',\n",
      "       ...\n",
      "       'mk-right_caudal-mean', 'mk-right_caudal-std', 'mk-right_caudal-skew',\n",
      "       'mk-right_caudal-kurt', 'mk-right_caudal-etrp',\n",
      "       'mk-corpus_callosum-mean', 'mk-corpus_callosum-std',\n",
      "       'mk-corpus_callosum-skew', 'mk-corpus_callosum-kurt',\n",
      "       'mk-corpus_callosum-etrp'],\n",
      "      dtype='object', length=280) Index(['Digit Span Backward T1'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "NegativeOnly = True\n",
    "\n",
    "if NegativeOnly:\n",
    "    X = data.iloc[negative_idx]\n",
    "    y = label.iloc[negative_idx]['Digit Span Backward T1']\n",
    "    \n",
    "else:\n",
    "    X = data\n",
    "    y = label['Digit Span Backward T1']\n",
    "\n",
    "drop = y.notnull()\n",
    "\n",
    "X = X[drop]\n",
    "y = y[drop]    \n",
    "\n",
    "y = y.to_frame()\n",
    "\n",
    "feature_coulmn = X.columns\n",
    "label_column = y.columns\n",
    "print(feature_coulmn, label_column)\n",
    "\n",
    "X = (X.values)\n",
    "y = (y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "Xs = X - np.mean(X, axis=0)[None, :]\n",
    "ncomp = 15\n",
    "pca = PCA(n_components=ncomp, whiten=True, svd_solver='randomized')\n",
    "pca.fit(Xs)\n",
    "sigma = pca.singular_values_\n",
    "PoV = [np.sum(sigma[:i]**2)/np.sum(sigma**2) for i in range(X.shape[1])]\n",
    "plt.plot(np.arange(X.shape[1]), PoV)\n",
    "Z = pca.transform(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(y))\n",
    "import matplotlib.cm as cm\n",
    "print (cm.hot(0.3))\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "\n",
    "for i in range (Z.shape[0]):\n",
    "        \n",
    "    plt.scatter(Z[i,0], Z[i,1], color=cm.hot((y[i]+2)/5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ztr, Zts, ytr, yts = train_test_split(Z, y, test_size=0.33)\n",
    "print(Ztr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVR(C=100, epsilon=0.5, kernel='rbf', degree=4, gamma=1, tol=0.001, cache_size=200, max_iter=-1)\n",
    "\n",
    "clf.fit(Ztr, ytr)\n",
    "\n",
    "ytr_hat = clf.predict(Ztr)\n",
    "yts_hat = clf.predict(Zts)\n",
    "\n",
    "train_score = r2_score(ytr, ytr_hat)\n",
    "test_score = r2_score(yts, yts_hat)\n",
    "\n",
    "# train_score = clf.score(Ztr, ytr)\n",
    "# yhat = clf.predict(Zts)\n",
    "# test_score = clf.score(yts, yhat)\n",
    "print(train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "Xs = (X - np.mean(X, axis=0)[None,:])/np.std(X, axis=0)[None,:]\n",
    "Xs = np.round(Xs, 1) # discrete the data\n",
    "y = y # y is already discrete number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdf = pd.DataFrame(Xs, columns=feature_coulmn)\n",
    "ydf = pd.DataFrame(y, columns=label_column)\n",
    "yXdf = pd.concat([ydf, Xdf], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eas_De_par-right_caudal-etrp', 'eas_De_perp-corpus_callosum-kurt', 'eas_De_perp-right_middle-kurt', 'mk-left_caudal-kurt', 'eas_De_par-corpus_callosum-skew', 'ias_Da-left_rostral-mean', 'FA-left_rostral-skew', 'awf-right_middle-skew', 'ak-left_rostral-etrp', 'ak-right_caudal-skew', 'awf-left_caudal-kurt', 'md-right_middle-kurt', 'ak-left_caudal-std', 'ak-left_rostral-skew', 'md-left_middle-etrp', 'eas_De_par-right_middle-std', 'ak-left_caudal-skew', 'md-left_middle-kurt', 'mk-right_caudal-skew', 'FA-left_middle-kurt', 'FA-right_rostral-kurt', 'ak-right_middle-mean', 'mk-left_middle-skew', 'ak-left_rostral-std', 'md-right_middle-skew', 'eas_De_par-left_rostral-etrp', 'ias_Da-corpus_callosum-std', 'awf-right_rostral-skew', 'ak-left_rostral-kurt', 'eas_De_perp-right_middle-std', 'eas_De_par-corpus_callosum-kurt', 'ak-right_middle-skew', 'md-right_middle-etrp', 'awf-right_rostral-mean', 'eas_De_par-corpus_callosum-mean', 'mk-left_rostral-std', 'ias_Da-right_caudal-etrp', 'awf-right_caudal-std', 'eas_De_par-left_rostral-skew', 'awf-right_caudal-skew', 'ias_Da-left_rostral-etrp', 'ak-right_rostral-skew', 'FA-right_caudal-kurt', 'eas_De_par-left_rostral-mean', 'mk-left_rostral-kurt', 'mk-left_middle-etrp', 'mk-right_middle-skew', 'md-left_middle-skew', 'eas_De_par-left_caudal-std', 'awf-left_middle-std']\n"
     ]
    }
   ],
   "source": [
    "selected_feat = pymrmr.mRMR(yXdf, 'MID', 50)\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NegativeOnly:\n",
    "    X = data.iloc[negative_idx][selected_feat]\n",
    "    y = label.iloc[negative_idx]['Digit Span Backward T1']\n",
    "    \n",
    "else:\n",
    "    X = data[selected_feat]\n",
    "    y = label['Digit Span Backward T1']\n",
    "\n",
    "drop = y.notnull()\n",
    "\n",
    "X = X[drop]\n",
    "y = y[drop]  \n",
    "\n",
    "Xnp = (X.values)\n",
    "ynp = (y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8768103607341309 0.2991228436180925\n"
     ]
    }
   ],
   "source": [
    "Xtr, Xts, ytr, yts = train_test_split(Xnp, ynp, test_size=0.33)\n",
    "# clf = svm.SVR(C=1000, epsilon=0.5, kernel='rbf', degree=4, gamma=0.01, tol=0.001, cache_size=200, max_iter=-1)\n",
    "clf = RandomForestRegressor(n_estimators=128, n_jobs=-1)\n",
    "clf.fit(Xtr, ytr)\n",
    "\n",
    "ytr_hat = clf.predict(Xtr)\n",
    "yts_hat = clf.predict(Xts)\n",
    "\n",
    "train_score = r2_score(ytr, ytr_hat)\n",
    "test_score = r2_score(yts, yts_hat)\n",
    "\n",
    "# train_score = clf.score(Ztr, ytr)\n",
    "# yhat = clf.predict(Zts)\n",
    "# test_score = clf.score(yts, yhat)\n",
    "print(train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "( 0.001 , 1e-05 ) value of (C, Gamma), and best feat indices= [11 30 10 24  3 44  1  4  0 36]\n",
      "( 0.001 , 0.0017782794100389228 ) value of (C, Gamma), and best feat indices= [11 30 10  4 36  0 45 14 24  6]\n",
      "( 0.001 , 0.31622776601683794 ) value of (C, Gamma), and best feat indices= [10 30 44  4  9 23 37 49 35 33]\n",
      "( 0.001 , 56.23413251903491 ) value of (C, Gamma), and best feat indices= [ 4 37 49 35 21 23 33 12 26  5]\n",
      "( 0.001 , 10000.0 ) value of (C, Gamma), and best feat indices= [23 49 33 26 15  5 37  6 12 35]\n",
      "( 0.03162277660168379 , 1e-05 ) value of (C, Gamma), and best feat indices= [11 30 10 24  3 44  1  4  0 36]\n",
      "( 0.03162277660168379 , 0.0017782794100389228 ) value of (C, Gamma), and best feat indices= [11 30 10  4 24 36 45  0 14 48]\n",
      "( 0.03162277660168379 , 0.31622776601683794 ) value of (C, Gamma), and best feat indices= [10 30 44  9 14 23 37 49 35 33]\n",
      "( 0.03162277660168379 , 56.23413251903491 ) value of (C, Gamma), and best feat indices= [ 4 33 37 49 35 21 23  5 12 26]\n",
      "( 0.03162277660168379 , 10000.0 ) value of (C, Gamma), and best feat indices= [23 49 33 26 37  5 15  6 12 35]\n",
      "( 1.0 , 1e-05 ) value of (C, Gamma), and best feat indices= [11  2 30 10 24  3 44 38  4 18]\n",
      "( 1.0 , 0.0017782794100389228 ) value of (C, Gamma), and best feat indices= [11 30 10 18  3  4 27 38 39 36]\n",
      "( 1.0 , 0.31622776601683794 ) value of (C, Gamma), and best feat indices= [ 4 10 27 14 20  9  5 33 19 35]\n",
      "( 1.0 , 56.23413251903491 ) value of (C, Gamma), and best feat indices= [ 1 32 26 33 12 49 37 23 35 21]\n",
      "( 1.0 , 10000.0 ) value of (C, Gamma), and best feat indices= [ 9 37 49 23 35 16 39 15  5 12]\n",
      "( 31.622776601683793 , 1e-05 ) value of (C, Gamma), and best feat indices= [11 30  1 10  3  4 45 14 36  9]\n",
      "( 31.622776601683793 , 0.0017782794100389228 ) value of (C, Gamma), and best feat indices= [30 10 47 14 20  9  4 42 19 39]\n",
      "( 31.622776601683793 , 0.31622776601683794 ) value of (C, Gamma), and best feat indices= [ 4  5 19 33 49  6 23 31 35 21]\n",
      "( 31.622776601683793 , 56.23413251903491 ) value of (C, Gamma), and best feat indices= [ 5 35 37 11 22 34 49 12 33 19]\n",
      "( 31.622776601683793 , 10000.0 ) value of (C, Gamma), and best feat indices= [17 43 37 49 26 22 33 44 35 15]\n",
      "( 1000.0 , 1e-05 ) value of (C, Gamma), and best feat indices= [30 10 44  3 47  4  1 38 45  9]\n",
      "( 1000.0 , 0.0017782794100389228 ) value of (C, Gamma), and best feat indices= [ 4 44 10 27  5 19 33 23 15 26]\n",
      "( 1000.0 , 0.31622776601683794 ) value of (C, Gamma), and best feat indices= [ 4 27 35 21  6 43 37 12 32 49]\n",
      "( 1000.0 , 56.23413251903491 ) value of (C, Gamma), and best feat indices= [ 5 11 19 35 49 12 34 22 37 33]\n",
      "( 1000.0 , 10000.0 ) value of (C, Gamma), and best feat indices= [17 43 37 49 26 22 33 44 35 15]\n",
      "maximum test accuracy= 0.384, achieved by using 10 features and ( C, Gamma, eps)= ( 1000.00000, 0.00178, 0.05000) from 14 metrics\n",
      "Selected feature for 3xiter= [ 4. 44. 10. 27.  5. 19. 33. 23. 15. 26.]\n",
      "['ak-left_rostral-etrp' 'awf-right_rostral-etrp' 'ak-left_middle-mean'\n",
      " 'ak-right_caudal-skew' 'ak-right_rostral-mean' 'ak-right_middle-etrp'\n",
      " 'ak-corpus_callosum-kurt' 'ak-left_caudal-kurt' 'ak-right_middle-mean'\n",
      " 'ak-right_caudal-std']\n",
      "total time= 60.54838013648987\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "num_feature = Xnp.shape[1]\n",
    "num_test = 20\n",
    "num_repeats = 5  ## shows number of times we shuffle the data and test on testing\n",
    "train_accuracies = [0] * num_repeats\n",
    "test_accuracies = [0] * num_repeats\n",
    "\n",
    "tot_num = Xnp.shape[0]\n",
    "\n",
    "num_selected = 10\n",
    "eps = 0.05\n",
    "\n",
    "C_range = np.logspace(-3, 3, num=5)\n",
    "gamma_range = np.logspace(-5, 4, 5)\n",
    "\n",
    "# C_range = np.array([31.62278])\n",
    "# gamma_range = np.array([0.31623])\n",
    "\n",
    "test_acc_all = np.zeros((C_range.shape[0], gamma_range.shape[0], num_feature))\n",
    "selected_feat = np.zeros((C_range.shape[0], gamma_range.shape[0], num_selected))\n",
    "\n",
    "print(\"Start\")\n",
    "for i in range(len(C_range)):\n",
    "    for j in range(len(gamma_range)):\n",
    "        a1, a2 = greedy_forward_SVM(Xnp, ynp, num_feature, num_selected, num_repeats, num_test, C_range[i], gamma_range[j],\n",
    "                                    eps)\n",
    "        a3 = np.asarray(a1)\n",
    "        test_acc_all[i, j, :] = a2\n",
    "        selected_feat[i, j, :] = a3\n",
    "        print(\"(\", C_range[i], \",\", gamma_range[j], \") value of (C, Gamma), and best feat indices=\", a3)\n",
    "\n",
    "max_ind = np.unravel_index(test_acc_all.argmax(), test_acc_all.shape)\n",
    "print(\"maximum test accuracy= %.3f, achieved by using %d features and ( C, Gamma, eps)= ( %.5f, %.5f, %.5f) from 14 metrics\" % (\n",
    "test_acc_all[max_ind], max_ind[2] + 1, C_range[max_ind[0]], gamma_range[max_ind[1]], eps))\n",
    "print(\"Selected feature for 3xiter=\", selected_feat[max_ind[0], max_ind[1], 0:max_ind[2] + 1])\n",
    "print(features[np.array(selected_feat[max_ind[0], max_ind[1], 0:max_ind[2] + 1], dtype=np.int)])\n",
    "# print(\"\\nMaximum Train Accuracy with 100 iteration: %f \" % np.max(train_acc_all), \"%\")\n",
    "# print(\"\\nMaximum Test Accuracy: %f, by feature indices= %s \" % ( np.max(test_acc_avg), subset_indices[best_testacc_ind[0]] ) )\n",
    "\n",
    "# print(\"\\nall accuracies:\", test_acc_avg)\n",
    "\n",
    "end_time = time.time()\n",
    "tot_time = end_time - start_time\n",
    "print(\"total time=\", tot_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch=1.0, CUDA=10.1",
   "language": "python",
   "name": "cs231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
